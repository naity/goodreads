{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "eeb0cdfb-7baf-429b-ba31-f41bc5f0536e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import torch\n",
    "import evaluate\n",
    "\n",
    "from tqdm.auto import tqdm\n",
    "from torch import nn\n",
    "from torch.optim import AdamW\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch.nn.functional import cross_entropy\n",
    "from sklearn.preprocessing import OrdinalEncoder\n",
    "from sklearn.model_selection import train_test_split\n",
    "from accelerate import Accelerator, notebook_launcher\n",
    "from accelerate.utils import set_seed\n",
    "from datasets import Dataset, DatasetDict\n",
    "from transformers import AutoTokenizer, AutoModel, AutoModelForSequenceClassification, \\\n",
    "    TrainingArguments, Trainer, get_scheduler, PretrainedConfig, PreTrainedModel\n",
    "\n",
    "np.random.seed(0) \n",
    "torch.manual_seed(0)\n",
    "\n",
    "device = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "46c69ab5-37b2-4041-8a9f-1b187efaef3b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>date_added</th>\n",
       "      <th>date_updated</th>\n",
       "      <th>read_at</th>\n",
       "      <th>started_at</th>\n",
       "      <th>n_votes</th>\n",
       "      <th>n_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>772215</th>\n",
       "      <td>e21627c07b1c16a64b1d55afb0801cd3</td>\n",
       "      <td>119324</td>\n",
       "      <td>003879c133a50fcf89372f653996629a</td>\n",
       "      <td>5</td>\n",
       "      <td>11/11/17 - 5/5 \\n This next installment wasn't...</td>\n",
       "      <td>Thu May 28 06:25:19 -0700 2015</td>\n",
       "      <td>Mon Sep 11 03:06:56 -0700 2017</td>\n",
       "      <td>Mon Sep 11 03:06:56 -0700 2017</td>\n",
       "      <td>Mon Sep 11 00:00:00 -0700 2017</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292046</th>\n",
       "      <td>6db54aa53cc7fe06339e1f381eb0b067</td>\n",
       "      <td>23126227</td>\n",
       "      <td>7187b3590d12c35d5d7b44c55ad67f1b</td>\n",
       "      <td>5</td>\n",
       "      <td>Totally enjoyed reading this. Owen and Nathan ...</td>\n",
       "      <td>Tue Jun 09 20:59:44 -0700 2015</td>\n",
       "      <td>Tue Jun 09 21:01:36 -0700 2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814437</th>\n",
       "      <td>1df102d3aa4d7e724ed2af9cab0e86c2</td>\n",
       "      <td>18190208</td>\n",
       "      <td>53dd1cf2d2bb0e64a08fdc2be8643bea</td>\n",
       "      <td>3</td>\n",
       "      <td>THE WITCH HUNTER was a quick, entertaining rea...</td>\n",
       "      <td>Sat Sep 27 11:35:31 -0700 2014</td>\n",
       "      <td>Sun Nov 08 08:37:58 -0800 2015</td>\n",
       "      <td>Wed Oct 07 00:00:00 -0700 2015</td>\n",
       "      <td>NaN</td>\n",
       "      <td>7</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381608</th>\n",
       "      <td>1558bfbf21cdfee8a8064a5abd3c9ae8</td>\n",
       "      <td>4671</td>\n",
       "      <td>730990b75ff5c3f76b81d58583b7cc88</td>\n",
       "      <td>5</td>\n",
       "      <td>I listened to The Great Gatsby on audio. I had...</td>\n",
       "      <td>Thu Aug 18 14:08:20 -0700 2011</td>\n",
       "      <td>Wed Oct 02 09:19:37 -0700 2013</td>\n",
       "      <td>Mon Aug 01 00:00:00 -0700 2011</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172519</th>\n",
       "      <td>2cba560652c041e9a14b7e25a92d6278</td>\n",
       "      <td>44538</td>\n",
       "      <td>af0143db98f00e3da41073c3c93ea2aa</td>\n",
       "      <td>5</td>\n",
       "      <td>Read if you like Jane Austen with more sex and...</td>\n",
       "      <td>Tue Apr 15 18:04:26 -0700 2008</td>\n",
       "      <td>Wed Mar 25 07:28:59 -0700 2015</td>\n",
       "      <td>Tue Apr 22 00:00:00 -0700 2008</td>\n",
       "      <td>NaN</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 user_id   book_id  \\\n",
       "772215  e21627c07b1c16a64b1d55afb0801cd3    119324   \n",
       "292046  6db54aa53cc7fe06339e1f381eb0b067  23126227   \n",
       "814437  1df102d3aa4d7e724ed2af9cab0e86c2  18190208   \n",
       "381608  1558bfbf21cdfee8a8064a5abd3c9ae8      4671   \n",
       "172519  2cba560652c041e9a14b7e25a92d6278     44538   \n",
       "\n",
       "                               review_id  rating  \\\n",
       "772215  003879c133a50fcf89372f653996629a       5   \n",
       "292046  7187b3590d12c35d5d7b44c55ad67f1b       5   \n",
       "814437  53dd1cf2d2bb0e64a08fdc2be8643bea       3   \n",
       "381608  730990b75ff5c3f76b81d58583b7cc88       5   \n",
       "172519  af0143db98f00e3da41073c3c93ea2aa       5   \n",
       "\n",
       "                                              review_text  \\\n",
       "772215  11/11/17 - 5/5 \\n This next installment wasn't...   \n",
       "292046  Totally enjoyed reading this. Owen and Nathan ...   \n",
       "814437  THE WITCH HUNTER was a quick, entertaining rea...   \n",
       "381608  I listened to The Great Gatsby on audio. I had...   \n",
       "172519  Read if you like Jane Austen with more sex and...   \n",
       "\n",
       "                            date_added                    date_updated  \\\n",
       "772215  Thu May 28 06:25:19 -0700 2015  Mon Sep 11 03:06:56 -0700 2017   \n",
       "292046  Tue Jun 09 20:59:44 -0700 2015  Tue Jun 09 21:01:36 -0700 2015   \n",
       "814437  Sat Sep 27 11:35:31 -0700 2014  Sun Nov 08 08:37:58 -0800 2015   \n",
       "381608  Thu Aug 18 14:08:20 -0700 2011  Wed Oct 02 09:19:37 -0700 2013   \n",
       "172519  Tue Apr 15 18:04:26 -0700 2008  Wed Mar 25 07:28:59 -0700 2015   \n",
       "\n",
       "                               read_at                      started_at  \\\n",
       "772215  Mon Sep 11 03:06:56 -0700 2017  Mon Sep 11 00:00:00 -0700 2017   \n",
       "292046                             NaN                             NaN   \n",
       "814437  Wed Oct 07 00:00:00 -0700 2015                             NaN   \n",
       "381608  Mon Aug 01 00:00:00 -0700 2011                             NaN   \n",
       "172519  Tue Apr 22 00:00:00 -0700 2008                             NaN   \n",
       "\n",
       "        n_votes  n_comments  \n",
       "772215        0           0  \n",
       "292046        1           0  \n",
       "814437        7           2  \n",
       "381608        0           0  \n",
       "172519        2           1  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = pd.read_csv(\"data/goodreads_train.csv\")\n",
    "train = train.sample(1000)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8cdfbb5e-0fca-4a34-9033-cef028529c5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>review_id</th>\n",
       "      <th>rating</th>\n",
       "      <th>review_text</th>\n",
       "      <th>date_added</th>\n",
       "      <th>date_updated</th>\n",
       "      <th>read_at</th>\n",
       "      <th>started_at</th>\n",
       "      <th>n_votes</th>\n",
       "      <th>n_comments</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [user_id, book_id, review_id, rating, review_text, date_added, date_updated, read_at, started_at, n_votes, n_comments]\n",
       "Index: []"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# the votes and comments are not reliable \n",
    "train.loc[train[\"book_id\"]==18245960, ].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05ba696b-d150-47c9-9926-3d7b4cd3f718",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>772215</th>\n",
       "      <td>e21627c07b1c16a64b1d55afb0801cd3</td>\n",
       "      <td>119324</td>\n",
       "      <td>11/11/17 - 5/5 \\n This next installment wasn't...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292046</th>\n",
       "      <td>6db54aa53cc7fe06339e1f381eb0b067</td>\n",
       "      <td>23126227</td>\n",
       "      <td>Totally enjoyed reading this. Owen and Nathan ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814437</th>\n",
       "      <td>1df102d3aa4d7e724ed2af9cab0e86c2</td>\n",
       "      <td>18190208</td>\n",
       "      <td>THE WITCH HUNTER was a quick, entertaining rea...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381608</th>\n",
       "      <td>1558bfbf21cdfee8a8064a5abd3c9ae8</td>\n",
       "      <td>4671</td>\n",
       "      <td>I listened to The Great Gatsby on audio. I had...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172519</th>\n",
       "      <td>2cba560652c041e9a14b7e25a92d6278</td>\n",
       "      <td>44538</td>\n",
       "      <td>Read if you like Jane Austen with more sex and...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                 user_id   book_id  \\\n",
       "772215  e21627c07b1c16a64b1d55afb0801cd3    119324   \n",
       "292046  6db54aa53cc7fe06339e1f381eb0b067  23126227   \n",
       "814437  1df102d3aa4d7e724ed2af9cab0e86c2  18190208   \n",
       "381608  1558bfbf21cdfee8a8064a5abd3c9ae8      4671   \n",
       "172519  2cba560652c041e9a14b7e25a92d6278     44538   \n",
       "\n",
       "                                              review_text  rating  \n",
       "772215  11/11/17 - 5/5 \\n This next installment wasn't...       5  \n",
       "292046  Totally enjoyed reading this. Owen and Nathan ...       5  \n",
       "814437  THE WITCH HUNTER was a quick, entertaining rea...       3  \n",
       "381608  I listened to The Great Gatsby on audio. I had...       5  \n",
       "172519  Read if you like Jane Austen with more sex and...       5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = train.loc[:, [\"user_id\", \"book_id\", \"review_text\", \"rating\"]]\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa6b34a5-3961-4340-ad5a-da526d40c1b1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[787., 123.],\n",
       "       [370., 768.],\n",
       "       [ 99., 634.],\n",
       "       [ 73.,  18.],\n",
       "       [162.,  77.]])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# encode user and book ids\n",
    "enc = OrdinalEncoder(handle_unknown=\"use_encoded_value\",\n",
    "                                   unknown_value=-1)\n",
    "encodings = enc.fit_transform(data[[\"user_id\", \"book_id\"]])\n",
    "\n",
    "# add 1 to X_train, so unknowns would be 0\n",
    "encodings = encodings + 1\n",
    "\n",
    "encodings[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "afbc7d22-2739-40fb-96ac-d59ef738b599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>user_id</th>\n",
       "      <th>book_id</th>\n",
       "      <th>review_text</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>772215</th>\n",
       "      <td>787</td>\n",
       "      <td>123</td>\n",
       "      <td>11/11/17 - 5/5 \\n This next installment wasn't...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>292046</th>\n",
       "      <td>370</td>\n",
       "      <td>768</td>\n",
       "      <td>Totally enjoyed reading this. Owen and Nathan ...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>814437</th>\n",
       "      <td>99</td>\n",
       "      <td>634</td>\n",
       "      <td>THE WITCH HUNTER was a quick, entertaining rea...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>381608</th>\n",
       "      <td>73</td>\n",
       "      <td>18</td>\n",
       "      <td>I listened to The Great Gatsby on audio. I had...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172519</th>\n",
       "      <td>162</td>\n",
       "      <td>77</td>\n",
       "      <td>Read if you like Jane Austen with more sex and...</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        user_id  book_id                                        review_text  \\\n",
       "772215      787      123  11/11/17 - 5/5 \\n This next installment wasn't...   \n",
       "292046      370      768  Totally enjoyed reading this. Owen and Nathan ...   \n",
       "814437       99      634  THE WITCH HUNTER was a quick, entertaining rea...   \n",
       "381608       73       18  I listened to The Great Gatsby on audio. I had...   \n",
       "172519      162       77  Read if you like Jane Austen with more sex and...   \n",
       "\n",
       "        rating  \n",
       "772215       5  \n",
       "292046       5  \n",
       "814437       3  \n",
       "381608       5  \n",
       "172519       5  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[\"user_id\"] = encodings[:, 0].astype(int)\n",
    "data[\"book_id\"] = encodings[:, 1].astype(int)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "a29b08c9-e2bb-4921-88b7-71bd898eaab8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "902 927\n"
     ]
    }
   ],
   "source": [
    "n_users, n_books = data[\"user_id\"].max() + 1, data[\"book_id\"].max() + 1\n",
    "print(n_users, n_books)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06a8a046-707c-417d-8f7d-bfde1296e23c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(900, 4) (100, 4)\n"
     ]
    }
   ],
   "source": [
    "# create a validation set\n",
    "train_df, valid_df = train_test_split(data, test_size=0.1, random_state=0)\n",
    "print(train_df.shape, valid_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c2cb6c34-94d0-48fb-8ee5-4a139f2a8f5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_model_name = \"distilbert-base-cased\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2138cd83-9ef6-4d51-aefc-8cb4823ae04e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(batch_size):\n",
    "    train_ds = Dataset.from_pandas(train_df)\n",
    "    valid_ds = Dataset.from_pandas(valid_df)\n",
    "    \n",
    "    dataset = DatasetDict()\n",
    "    dataset[\"train\"] = train_ds\n",
    "    dataset[\"valid\"] = valid_ds\n",
    "    \n",
    "    tokenizer = AutoTokenizer.from_pretrained(transformer_model_name)\n",
    "    tokenizer.save_pretrained(\"models/tokenizer/\")\n",
    "    \n",
    "    def tokenize_func(dataset, col=\"review_text\"):\n",
    "        return tokenizer(dataset[col], padding=\"max_length\", truncation=True)\n",
    "    \n",
    "    tokenized_datasets = dataset.map(tokenize_func, batched=True)\n",
    "    \n",
    "    tokenized_datasets = tokenized_datasets.remove_columns(\n",
    "        [\"review_text\", \"__index_level_0__\"])\n",
    "    tokenized_datasets = tokenized_datasets.rename_column(\"rating\", \"labels\")\n",
    "    tokenized_datasets.set_format(\"torch\")\n",
    "    \n",
    "    train_dl = DataLoader(tokenized_datasets[\"train\"],\n",
    "                      shuffle=True,\n",
    "                      batch_size=batch_size)\n",
    "    valid_dl = DataLoader(tokenized_datasets[\"valid\"],\n",
    "                          batch_size=batch_size)\n",
    "    return train_dl, valid_dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df7d0063-4457-48c5-8f1c-638a9805b504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "32feb8985da6413587dd1146820a44b2",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b485b04d75f84159b3d795ea6cf6a278",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_dl, valid_dl = get_dataloaders(8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0ec45977-c58e-42b1-a3d1-a4b5a10bbc65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'user_id': tensor([ 76, 822, 304, 451, 458, 161, 716, 196]),\n",
       " 'book_id': tensor([731, 119, 271, 273, 809, 686, 233, 383]),\n",
       " 'labels': tensor([5, 4, 5, 3, 5, 4, 4, 5]),\n",
       " 'input_ids': tensor([[  101, 13432,  1158,  ...,     0,     0,     0],\n",
       "         [  101,  6355,  1330,  ...,     0,     0,     0],\n",
       "         [  101,   125,   119,  ...,     0,     0,     0],\n",
       "         ...,\n",
       "         [  101,  3274,  5016,  ...,  2147,  1114,   102],\n",
       "         [  101,   146,  8050,  ...,     0,     0,     0],\n",
       "         [  101,  2131,  1105,  ...,     0,     0,     0]]),\n",
       " 'attention_mask': tensor([[1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [1, 1, 1,  ..., 1, 1, 1],\n",
       "         [1, 1, 1,  ..., 0, 0, 0],\n",
       "         [1, 1, 1,  ..., 0, 0, 0]])}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch = next(iter(train_dl))\n",
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b68eb6fd-e5e7-4e9a-b8f3-9b6d989bacbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedConfig(PretrainedConfig):\n",
    "    def __init__(self, **kwargs):\n",
    "        super().__init__(**kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "6b90d06a-9ef8-4f90-8098-9c6ced777903",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CombinedModel(PreTrainedModel):\n",
    "    def __init__(self, config, n_users, n_books, transformer_model_name,\n",
    "                 n_factors=50, n_classes=6):\n",
    "        super().__init__(config)\n",
    "        self.user_embs = nn.Embedding(n_users, n_factors)\n",
    "        self.book_embs = nn.Embedding(n_books, n_factors)\n",
    "        self.text_transformer = AutoModelForSequenceClassification.from_pretrained(\n",
    "            transformer_model_name, num_labels=512)\n",
    "        self.linear_layers = nn.Sequential(\n",
    "            nn.Linear(n_factors*2+512, 256, bias=False),\n",
    "            nn.LeakyReLU(),\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(),\n",
    "            nn.Linear(256, n_classes)\n",
    "        )\n",
    "        \n",
    "    def forward(self, user_id=None, book_id=None,\n",
    "                input_ids=None, attention_mask=None, labels=None):\n",
    "        # first col: users, second col: books\n",
    "        x_users = self.user_embs(user_id)\n",
    "        x_books = self.book_embs(book_id)\n",
    "        x_transformer = self.text_transformer(input_ids=input_ids,\n",
    "                                              attention_mask=attention_mask).logits\n",
    "        x = torch.cat([x_users, x_books, x_transformer], dim=-1)\n",
    "        logits =  self.linear_layers(x)\n",
    "        \n",
    "        if labels is not None:\n",
    "            loss = cross_entropy(logits, labels)\n",
    "            return {\"loss\": loss, \"logits\": logits}\n",
    "        \n",
    "        return {\"logits\": logits}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b7df7cb1-1583-45d5-921f-910096b14d1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "CombinedModel(\n",
       "  (user_embs): Embedding(902, 50)\n",
       "  (book_embs): Embedding(927, 50)\n",
       "  (text_transformer): DistilBertForSequenceClassification(\n",
       "    (distilbert): DistilBertModel(\n",
       "      (embeddings): Embeddings(\n",
       "        (word_embeddings): Embedding(28996, 768, padding_idx=0)\n",
       "        (position_embeddings): Embedding(512, 768)\n",
       "        (LayerNorm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (transformer): Transformer(\n",
       "        (layer): ModuleList(\n",
       "          (0): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (1): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (2): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (3): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (4): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "          (5): TransformerBlock(\n",
       "            (attention): MultiHeadSelfAttention(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (q_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (k_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (v_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "              (out_lin): Linear(in_features=768, out_features=768, bias=True)\n",
       "            )\n",
       "            (sa_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "            (ffn): FFN(\n",
       "              (dropout): Dropout(p=0.1, inplace=False)\n",
       "              (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "              (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "              (activation): GELUActivation()\n",
       "            )\n",
       "            (output_layer_norm): LayerNorm((768,), eps=1e-12, elementwise_affine=True)\n",
       "          )\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (pre_classifier): Linear(in_features=768, out_features=768, bias=True)\n",
       "    (classifier): Linear(in_features=768, out_features=512, bias=True)\n",
       "    (dropout): Dropout(p=0.2, inplace=False)\n",
       "  )\n",
       "  (linear_layers): Sequential(\n",
       "    (0): Linear(in_features=612, out_features=256, bias=False)\n",
       "    (1): LeakyReLU(negative_slope=0.01)\n",
       "    (2): BatchNorm1d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
       "    (3): Dropout(p=0.5, inplace=False)\n",
       "    (4): Linear(in_features=256, out_features=6, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def get_model():\n",
    "    config = CombinedConfig()\n",
    "    model = CombinedModel(config, n_users, n_books, transformer_model_name)\n",
    "    return model\n",
    "\n",
    "model = get_model()\n",
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6055d6cf-6ec3-4670-b24b-6d18f09b5115",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': tensor(2.2753, grad_fn=<NllLossBackward0>),\n",
       " 'logits': tensor([[ 0.7709, -1.1219,  0.0567,  0.1525,  1.1508, -0.4862],\n",
       "         [-0.1105, -0.0502,  1.0535,  1.4727,  0.4887,  0.3666],\n",
       "         [ 0.1450,  1.2135,  0.6036,  0.1206,  0.6247,  1.4563],\n",
       "         [ 1.0750,  0.2399, -0.5787,  0.1669,  0.3621,  1.1503],\n",
       "         [-0.4572,  0.9289,  1.2784,  0.5159, -0.4233, -0.1340],\n",
       "         [ 0.1771,  0.0514,  0.3022, -0.6492, -0.5052, -1.5077],\n",
       "         [ 0.6737, -0.1828, -0.2362,  0.7395, -0.5491,  0.8389],\n",
       "         [ 0.2444, -0.5964,  0.6709, -0.6026, -1.2856, -1.4115]],\n",
       "        grad_fn=<AddmmBackward0>)}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model(**batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a9f185b7-39eb-43d8-9be1-f8665eac6e50",
   "metadata": {},
   "outputs": [],
   "source": [
    "def training_loop(batch_size=8, lr=5e-5, num_epochs=3,\n",
    "                  mixed_precision=\"fp16\", seed=0):\n",
    "    # set_seed(seed)\n",
    "    # accelerator = Accelerator(mixed_precision=mixed_precision)\n",
    "    model = get_model()\n",
    "    model.to(device)\n",
    "    train_dl, valid_dl = get_dataloaders(batch_size)\n",
    "    \n",
    "    num_training_steps = num_epochs * len(train_dl)\n",
    "    optimizer = AdamW(model.parameters(), lr=lr)\n",
    "    lr_scheduler = get_scheduler(\n",
    "        name=\"linear\",\n",
    "        optimizer=optimizer,\n",
    "        num_warmup_steps=0,\n",
    "        num_training_steps=num_training_steps)\n",
    "    \n",
    "    # model, optimizer, train_dl, valid_dl, lr_scheduler = accelerator.prepare(\n",
    "    #     model, optimizer, train_dl, valid_dl, lr_scheduler)\n",
    "    \n",
    "    progress_bar = tqdm(range(num_training_steps))\n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        for batch in train_dl:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs[\"loss\"]\n",
    "            loss.backward()\n",
    "            #accelerator.backward(loss)\n",
    "\n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "            progress_bar.update(1)\n",
    "\n",
    "        model.eval()\n",
    "        accurate = 0\n",
    "        num_elems = 0\n",
    "        for batch in valid_dl:\n",
    "            batch = {k: v.to(device) for k, v in batch.items()}\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "\n",
    "            logits = outputs[\"logits\"]\n",
    "            predictions = torch.argmax(logits, dim=-1)\n",
    "            # accurate_preds = accelerator.gather(predictions) == accelerator.gather(batch[\"labels\"])\n",
    "            accurate_preds = predictions == batch[\"labels\"]\n",
    "            num_elems += accurate_preds.shape[0]\n",
    "            accurate += accurate_preds.long().sum()\n",
    "            \n",
    "        accuracy = accurate.item() / num_elems\n",
    "        #accelerator.print(f\"Epoch {epoch+1} accuracy: {100*accuracy:.2f}%\")\n",
    "        print(f\"Epoch {epoch+1} accuracy: {100*accuracy:.2f}%\")\n",
    "        \n",
    "    # save model\n",
    "    # accelerator.wait_for_everyone()\n",
    "    # model = accelerator.unwrap_model(model)\n",
    "    model.save_pretrained(f\"models/combined_v1/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d24a2f69-1a95-4bb8-b05a-787f6e31d65a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at distilbert-base-cased were not used when initializing DistilBertForSequenceClassification: ['vocab_layer_norm.bias', 'vocab_layer_norm.weight', 'vocab_transform.weight', 'vocab_transform.bias', 'vocab_projector.weight', 'vocab_projector.bias']\n",
      "- This IS expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DistilBertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DistilBertForSequenceClassification were not initialized from the model checkpoint at distilbert-base-cased and are newly initialized: ['pre_classifier.weight', 'classifier.bias', 'pre_classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4f66b031005f413f80313eb94f2ec21a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "39f18941cf98499cb64cb3b99f83db3a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1 [00:00<?, ?ba/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "74a9f8dc19b14081a5bce8cb67a3ae9a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/1130 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1 accuracy: 24.00%\n",
      "Epoch 2 accuracy: 22.00%\n",
      "Epoch 3 accuracy: 22.00%\n",
      "Epoch 4 accuracy: 21.00%\n",
      "Epoch 5 accuracy: 20.00%\n",
      "Epoch 6 accuracy: 22.00%\n",
      "Epoch 7 accuracy: 21.00%\n",
      "Epoch 8 accuracy: 21.00%\n",
      "Epoch 9 accuracy: 21.00%\n",
      "Epoch 10 accuracy: 24.00%\n"
     ]
    }
   ],
   "source": [
    "training_loop(batch_size=8, num_epochs=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "1e5787b9-0910-43d9-afe3-e7e554b58979",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_gpus = torch.cuda.device_count()\n",
    "# num_gpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "c4b63d96-1cf7-4322-b553-84cd12d3348f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args = (32, 5e-5, 3, \"fp16\", 0)\n",
    "# notebook_launcher(training_loop, args, num_processes=num_gpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e526c3d-2247-4c60-9164-86882adee6b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
